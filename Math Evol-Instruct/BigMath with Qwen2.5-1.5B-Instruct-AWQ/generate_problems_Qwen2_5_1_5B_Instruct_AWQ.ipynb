{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxlWJpjCrZjnauOurs7EGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Man-snow/llm2025compet_Man-snow/blob/main/Math%20Evol-Instruct/BigMath%20with%20DeepSeek-R1-0528/generate_problems_Qwen2_5_1_5B_Instruct_AWQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tgd_8csRXGTv"
      },
      "outputs": [],
      "source": [
        "!pip install vllm==0.5.1 datasets pandas \"transformers>=4.42.0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !!修正!!: login()ヘルパーを使わず、トークンを直接変数に格納する方式に変更\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "from vllm import LLM, SamplingParams\n",
        "import re\n",
        "from transformers import AutoTokenizer\n",
        "from IPython.display import display\n",
        "import getpass\n",
        "\n",
        "# このセルを実行すると表示される入力ボックスに、「Write」権限を持つトークンを貼り付けてください。\n",
        "# 入力した文字は表示されませんが、正常に入力されています。\n",
        "hf_write_token = getpass.getpass(\"Hugging Face Write Token:\")\n",
        "print(\"Token received.\")"
      ],
      "metadata": {
        "id": "npl0WvRpXOJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 定数設定 ---\n",
        "MODEL_ID = \"Qwen/Qwen2.5-1.5B-Instruct-AWQ\"\n",
        "SOURCE_DATASET_ID = \"SynthLabsAI/Big-Math-RL-Verified\"\n",
        "# !!修正!!: Hugging Face Hubのアップロード先リポジトリIDを指定\n",
        "OUTPUT_DATASET_ID = \"Man-snow/test_evolved-math-problems\"\n",
        "\n",
        "# 問題を上方修正するためのプロンプト\n",
        "UPWARD_EVOLUTION_PROMPT_TEMPLATE = \"\"\"\n",
        "You are an expert in creating complex mathematical problems. Your task is to rewrite the given instruction to make it more challenging.\n",
        "\n",
        "#Instruction#\n",
        "{problem}\n",
        "\n",
        "Follow these steps precisely.\n",
        "Step 1: Understand the core concept and structure of the \"#Instruction#\". Identify the key elements such as variables, conditions, participants, actions, or processes that can be manipulated to increase complexity. Also, recognize the theme of the instruction and ensure it remains consistent throughout the evolution.\n",
        "Step 2: Formulate a comprehensive plan to increment the complexity of the \"#Instruction#\" based on the identified elements in Step 1. The plan should involve modifying or expanding at least three components from the list. It is crucial to ensure that all components in the instruction are logically interconnected and that the complexity increase is coherent and justified. The plan should avoid introducing variables or conditions without clear criteria for determining their values or without contributing to the overall complexity. In this step, consider adding more real-world constraints and dependencies between variables to make the problem more challenging. And you can also add more constraints, concretizing, increasing reasoning.\n",
        "Step 3: Implement the plan step by step to create the \"#Rewritten Instruction#\". Ensure the rewritten instruction maintains a logical sequence and avoids ambiguity or confusion. If additional variables or conditions are introduced, provide clear and unambiguous methods or criteria for determining their values. The \"#Rewritten Instruction#\" should not exceed the original \"#Instruction#\" by more than 30 words to ensure readability and comprehension.\n",
        "Step 4: Review the \"#Rewritten Instruction#\" thoroughly to identify any unreasonable elements or inconsistencies. Make sure the \"#Rewritten Instruction#\" is a more complex version of the \"#Instruction#\". and that it accurately reflects the intended increase in complexity. Adjust any part of the instruction that may lead to misunderstanding or ambiguity, and provide the \"#Finally Rewritten Instruction#\" without any supplementary explanation.\n",
        "Please reply strictly in the following format:\n",
        "Step 1\n",
        "#Elements Identified#:\n",
        "...\n",
        "Step 2\n",
        "#Plan#:\n",
        "...\n",
        "Step 3\n",
        "#Rewritten Instruction#:\n",
        "...\n",
        "Step 4\n",
        "#Finally Rewritten Instruction#:\n",
        "...\n",
        "\"\"\"\n",
        "\n",
        "# --- ヘルパー関数 ---\n",
        "def parse_final_instruction(text: str) -> str | None:\n",
        "    \"\"\"\n",
        "    モデルの出力から\"#Finally Rewritten Instruction#\"の部分を抽出する。\n",
        "    見つからない場合はNoneを返す。\n",
        "    \"\"\"\n",
        "    match = re.search(r\"#Finally Rewritten Instruction#:\\s*(.*)\", text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return None\n",
        "\n",
        "print(\"定数とヘルパー関数の定義が完了しました。\")"
      ],
      "metadata": {
        "id": "okiNyTXkXRaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- ステップ1: データセットの準備 ---\")\n",
        "try:\n",
        "    dataset = load_dataset(SOURCE_DATASET_ID, split=\"train\", trust_remote_code=True)\n",
        "    df = dataset.to_pandas()\n",
        "    sorted_df = df.sort_values(by=[\"llama8b_solve_rate\", \"problem\"], ascending=[True, True])\n",
        "    problems_to_process = sorted_df.head(100)\n",
        "    print(f\"データセットの準備が完了しました。処理対象: {len(problems_to_process)}問\")\n",
        "except Exception as e:\n",
        "    print(f\"データセットの読み込みに失敗しました: {e}\")"
      ],
      "metadata": {
        "id": "ILJv2VASXWeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- ステップ2: vLLMモデルの初期化 ---\")\n",
        "try:\n",
        "    llm = LLM(\n",
        "        model=MODEL_ID,\n",
        "        quantization=\"awq\",\n",
        "        trust_remote_code=True,\n",
        "        gpu_memory_utilization=0.9\n",
        "    )\n",
        "    sampling_params = SamplingParams(temperature=0.7, top_p=0.95, max_tokens=1024)\n",
        "    print(\"モデルの初期化が完了しました。\")\n",
        "except Exception as e:\n",
        "    print(f\"モデルの初期化に失敗しました: {e}\")"
      ],
      "metadata": {
        "id": "jd-hr05rom1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- ステップ3 & 4: 問題生成と結果の集計 ---\")\n",
        "# GemmaのInstructモデルのテンプレートに合わせてプロンプトを整形\n",
        "prompts = [\n",
        "    f\"<start_of_turn>user\\n{UPWARD_EVOLUTION_PROMPT_TEMPLATE.format(problem=row['problem'])}<end_of_turn>\\n<start_of_turn>model\"\n",
        "    for _, row in problems_to_process.iterrows()\n",
        "]\n",
        "\n",
        "start_time = time.time()\n",
        "outputs = llm.generate(prompts, sampling_params)\n",
        "end_time = time.time()\n",
        "total_elapsed_time = end_time - start_time\n",
        "print(f\"問題生成が完了しました。処理時間: {total_elapsed_time:.2f}秒\")\n",
        "\n",
        "# 結果の集計\n",
        "results = []\n",
        "for i, output in enumerate(outputs):\n",
        "    original_problem_text = problems_to_process.iloc[i]['problem']\n",
        "    generated_text = output.outputs[0].text\n",
        "    evolved_problem = parse_final_instruction(generated_text)\n",
        "    avg_time_per_problem = total_elapsed_time / len(outputs) if len(outputs) > 0 else 0\n",
        "\n",
        "    results.append({\n",
        "        \"original_problem\": original_problem_text,\n",
        "        \"evolved_problem\": evolved_problem,\n",
        "        \"total_tokens\": len(output.outputs[0].token_ids),\n",
        "        \"elapsed_time_avg\": avg_time_per_problem,\n",
        "        \"success\": evolved_problem is not None,\n",
        "        \"full_model_output\": generated_text\n",
        "    })\n",
        "print(\"結果の集計が完了しました。\")"
      ],
      "metadata": {
        "id": "H0VG-kXsoqJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- ステップ5: 結果の保存とプレビュー ---\")\n",
        "results_df = pd.DataFrame(results)\n",
        "output_filename = \"results.csv\"\n",
        "results_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "print(f\"結果を'{output_filename}'に保存しました。\")\n",
        "\n",
        "# 結果のプレビューを表示\n",
        "print(\"\\n--- 生成データ プレビュー ---\")\n",
        "display(results_df.head())"
      ],
      "metadata": {
        "id": "uiSQKzexoro4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- ステップ6: Hugging Face Hubへのアップロードとプレビュー ---\")\n",
        "try:\n",
        "    # 結果をpandas DataFrameに変換\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # pandas DataFrameからHugging Face Datasetオブジェクトに変換\n",
        "    hf_dataset = Dataset.from_pandas(results_df)\n",
        "\n",
        "    # !!修正!!: セル2で受け取ったトークンを直接指定してアップロード\n",
        "    hf_dataset.push_to_hub(\n",
        "        repo_id=OUTPUT_DATASET_ID,\n",
        "        private=True, # 非公開データセットとして作成する場合はTrue\n",
        "        token=hf_write_token\n",
        "    )\n",
        "    print(f\"データセットを '{OUTPUT_DATASET_ID}' に正常にアップロードしました。\")\n",
        "\n",
        "    # 結果のプレビューを表示\n",
        "    print(\"\\n--- 生成データ プレビュー ---\")\n",
        "    display(results_df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Hugging Face Hubへのアップロードに失敗しました: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "KyFQilgfzPEQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
